{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naming CNN Layers\n",
    "## Preface\n",
    "This notebook is another copy of post \\#11, however, in this post, I'm modifying my CNN to have dedicated \"names\" at each layer. The names will be important for my next post because it will allow me to access the filters within each convolutional layer and view them. Nothing really new in this post here either except when I define the _**convnet**_ layers in TFlearn. You'll see that each of them have a _**name**_ parameter attached to it as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import math\n",
    "import boto3\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily load from np arrays\n",
    "chi_photos_np = np.load('chi_photos_np_0.03_compress.npy')\n",
    "lars_photos_np = np.load('lars_photos_np_0.03_compress.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 91, 91)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View shape of numpy array\n",
    "chi_photos_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set width var\n",
    "width = chi_photos_np.shape[-1]\n",
    "width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try out scaler on a manually set data (min of 0, max of 255)\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0],\n",
       "       [255]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set test data list to train on (min of 0, max of 255)\n",
    "test_list = np.array([0, 255]).reshape(-1, 1)\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chiwang/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit test list\n",
    "scaler.fit(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping 3D Array To 4D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 91, 91, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_photos_np.reshape(-1, width, width, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135, 139, 139, ..., 210, 142, 136]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to prepare for scaler\n",
    "chi_photos_np_flat = chi_photos_np.reshape(1, -1)\n",
    "chi_photos_np_flat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52941176,  0.54509804,  0.54509804, ...,  0.82352941,\n",
       "         0.55686275,  0.53333333]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale\n",
    "chi_photos_np_scaled = scaler.transform(chi_photos_np_flat)\n",
    "chi_photos_np_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape to prepare for scaler\n",
    "lars_photos_np_flat = lars_photos_np.reshape(1, -1)\n",
    "lars_photos_np_scaled = scaler.transform(lars_photos_np_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi_photos_reshaped has shape: (203, 91, 91, 1)\n",
      "lars_photos_reshaped has shape: (200, 91, 91, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "chi_photos_reshaped = chi_photos_np_scaled.reshape(-1, width, width, 1)\n",
    "lars_photos_reshaped = lars_photos_np_scaled.reshape(-1, width, width, 1)\n",
    "\n",
    "print('{} has shape: {}'. format('chi_photos_reshaped', chi_photos_reshaped.shape))\n",
    "print('{} has shape: {}'. format('lars_photos_reshaped', lars_photos_reshaped.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_input has shape: (203, 91, 91, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create copy of chi's photos to start populating x_input\n",
    "x_input = copy.deepcopy(chi_photos_reshaped)\n",
    "\n",
    "print('{} has shape: {}'. format('x_input', x_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_input has shape: (403, 91, 91, 1)\n"
     ]
    }
   ],
   "source": [
    "# Concatentate lars' photos to existing x_input\n",
    "x_input = np.append(x_input, lars_photos_reshaped, axis = 0)\n",
    "\n",
    "print('{} has shape: {}'. format('x_input', x_input.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_chi has shape: (203, 2)\n",
      "y_lars has shape: (200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create label arrays\n",
    "y_chi = np.array([[1, 0] for i in chi_photos_reshaped])\n",
    "y_lars = np.array([[0, 1] for i in lars_photos_reshaped])\n",
    "\n",
    "print('{} has shape: {}'. format('y_chi', y_chi.shape))\n",
    "print('{} has shape: {}'. format('y_lars', y_lars.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first few elements\n",
    "y_chi[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_input has shape: (203, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create copy of chi's labels to start populating y_input\n",
    "y_input = copy.deepcopy(y_chi)\n",
    "\n",
    "print('{} has shape: {}'. format('y_input', y_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_input has shape: (403, 2)\n"
     ]
    }
   ],
   "source": [
    "# Concatentate lars' labels to existing y_input\n",
    "y_input = np.append(y_input, y_lars, axis = 0)\n",
    "\n",
    "print('{} has shape: {}'. format('y_input', y_input.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "I'm going to just copy and paste the CNN structure I used for the MNIST tutorial and see what happens. I'm running this on my own laptop by the way, let's observe the speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TFlearn libraries\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentdex's code to build the neural net using tflearn\n",
    "#   Input layer --> conv layer w/ max pooling --> conv layer w/ max pooling --> fully connected layer --> output layer\n",
    "convnet = input_data(shape = [None, width, width, 1], name = 'input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 10, activation = 'relu', name = 'conv_1')\n",
    "convnet = max_pool_2d(convnet, 2, name = 'max_pool_1')\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 10, activation = 'relu', name = 'conv_2')\n",
    "convnet = max_pool_2d(convnet, 2, name = 'max_pool_2')\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation = 'relu', name = 'fully_connected_1')\n",
    "convnet = dropout(convnet, 0.8, name = 'dropout_1')\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation = 'softmax', name = 'fully_connected_2')\n",
    "convnet = regression(convnet, optimizer = 'sgd', learning_rate = 0.01, loss = 'categorical_crossentropy', name = 'targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403, 91, 91, 1)\n",
      "(403, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_input.shape)\n",
    "print(y_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_input, y_input, test_size = 0.1, stratify = y_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.01719\u001b[0m\u001b[0m | time: 168.873s\n",
      "| SGD | epoch: 003 | loss: 0.01719 - acc: 0.9999 -- iter: 704/724\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.01582\u001b[0m\u001b[0m | time: 194.779s\n",
      "| SGD | epoch: 003 | loss: 0.01582 - acc: 0.9999 | val_loss: 0.00960 - val_acc: 1.0000 -- iter: 724/724\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Train with data\n",
    "model = tflearn.DNN(convnet)\n",
    "model.fit(\n",
    "    {'input': x_train},\n",
    "    {'targets': y_train},\n",
    "    n_epoch = 3,\n",
    "    validation_set = ({'input': x_test}, {'targets': y_test}),\n",
    "    snapshot_step = 500,\n",
    "    show_metric = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/chiwang/Documents/Projects/Dev/chi_lars_face_detection/notebook/model_4_epochs_0.03_compression_99.6_named.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save('model_4_epochs_0.03_compression_99.6_named.tflearn')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
