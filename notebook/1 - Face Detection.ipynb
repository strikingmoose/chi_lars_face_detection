{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection\n",
    "## Introduction\n",
    "Hello! Back at it with another little project. Up till now, I've gotten quite familiar with most of the basic linear and non-linear classification methods...\n",
    "- I used basic linear (LDA, QDA, Logistic Regression) and non-linear methods (SVM, Trees, Gradient Boosted Trees, Basic NN) to predict the 2016-2017 All-NBA players\n",
    "- I used gradient boosting to classify easy listening and rock songs\n",
    "- I used gradient boosting and KNN to create a geographical heatmap of my home city's (Edmonton) most expensive neighbourhoods\n",
    "\n",
    "I've been using a lot of very highly non-linear methods. I've actually thought about finding a use case where I could build more interpretable models (a la linear regression / single decision tree) but, in a turn of events, I'm actually going to go in the opposite direction and build an even more complex non-linear model in this series of posts haha...\n",
    "\n",
    "<img src = \"https://media.tenor.com/images/9bd5c596039a994026b66867fe533303/tenor.gif\" width = \"400px\">\n",
    "\n",
    "I tried man... I really tried... I told myself at one point I would stay away from Neural Networks because I know how big of a rabbit hole they are. You got NN's, deep NNs, convolutional NNs, recurrent NNs... and that's just from someone who's been watching Youtube videos.\n",
    "\n",
    "There are a few reasons why I decided to proceed with a deep learning project:\n",
    "1. I had no idea how easy it was to spin up a NN these days...\n",
    "2. I think I've built a decent set of fundamentals for machine learning, my objectives over the last few projects were absolutely to become familiar with different models, but that was only part of the story. The other part is that I wanted to build good habits and practices when I try to solve machine learning problems. This involved understanding the bias-variance trade-off, practicing _**cross-validation**_ approaches, understanding how to tweak parameters easily and effectively, and simply becoming familiar with a common workflow in building models... through Python, I've been able to at least scratch the surface of all of these skills!\n",
    "3. I wanted to integrate my machine learning knowledge so far with infrastructure knowledge. The last couple of times I've used gradient boosting, I've ended up sitting around for up to 2-3 hours at a time training my model. It's generally the cross-validation that kills me. Both NN and Gradient Boosted Tree tools nowadays (e.g. Tensorflow, xgboost respectively) come with multi-threaded GPU capabilities. The problem? The GPU on the Mac that I'm using to write this leaves something to be desired. In the case of Tensorflow, Mac-based GPU processing isn't even supported! This gives me an opportunity to get into AWS and infrastructure automation / design a little bit.\n",
    "\n",
    "I'm sure I haven't convinced you that I'm ready to take on a Neural Network (I haven't even convinced myself), but let's get this show on the road.\n",
    "\n",
    "## Face Detection of Chi and Larissa\n",
    "Good ol' face detection...\n",
    "\n",
    "<img src = \"http://i.imgur.com/2Ys4lIJ.gif\", width = \"400px\">\n",
    "\n",
    "I'm going to do some very simple face detection in this project. I'm going to try to build a convolutional NN that can tell the difference between me and my girlfriend, Larissa. Only 2 classes to identify, not too many photos each (I'll aim for 100 - 200), hopefully pretty straightforward and simple... at least simple enough for me to kind of learn what's going on.\n",
    "\n",
    "I want to start super simple because just thinking about face detection hurts... my face.\n",
    "\n",
    "<img src = \"http://s3.amazonaws.com/images.hitfix.com/assets/2780/face.gif\" width = \"300px\">\n",
    "\n",
    "There are so many factors...\n",
    "- Dynamic characteristics (hair, facial expression, facial hair, makeup)\n",
    "- Clothing and accessories (glasses, top, hat)\n",
    "- Face size on picture\n",
    "- Face orientation on picture\n",
    "- Photographic properties of picture (brightness, contrast, white balance, focus, color tint)\n",
    "- Photo background\n",
    "\n",
    "Because of this, I tried to make this as easy for myself as possible. I tried to eliminate any of the factors above that could have contributed in a more complex task for the model (perhaps some of these can be tested later on, though!). I'll go with the following controlled variables:\n",
    "- I will train on different facial expressions, but hair and makeup will remain constant (no makeup, and no hair in my case har har har)\n",
    "- No extra clothing or accessories other than the shirt that will be worn at the time of taking the photo\n",
    "- Standardized face size\n",
    "- Standardized face orientation\n",
    "- Standardized photographic properties as all photos will be taken on my iPhone in similar lighting conditions\n",
    "- White / light colored wall as background\n",
    "\n",
    "This should provide enough of an introduction before I need to get into convolutional NNs, so let's stop here and continue in the next post!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
